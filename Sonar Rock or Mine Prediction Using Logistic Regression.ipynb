{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3209439f",
   "metadata": {},
   "source": [
    "# Sonar Rock or Mine Prediction using Logistic Regression\n",
    "\n",
    "![Sonar Rock vs Mine Detection](Banner.jpg)\n",
    "\n",
    "\n",
    "\n",
    "Yeah, I made this Image\n",
    "\n",
    "## Introduction\n",
    "This project focuses on the prediction of underwater objects as either rocks or mines using sonar data. Sonar, short for Sound Navigation and Ranging, is a technique that uses sound waves to detect and locate objects underwater. By analyzing the echoes produced by these sound waves, we can gather information about the objects present in the water.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The objective of this project is to develop a predictive model that can classify the detected objects as either rocks or mines based on the sonar data. To achieve this, we will employ logistic regression, a popular machine learning algorithm for binary classification tasks.\n",
    "\n",
    "## Dataset\n",
    "The dataset used for this project contains a collection of sonar signals, each corresponding to a specific object detected underwater. The signals were obtained by bouncing sound waves off the objects and recording the returning echoes. For each signal, a set of numerical features were extracted, representing various characteristics of the echoes.\n",
    "\n",
    "The dataset is labeled, with each object categorized as either a rock or a mine. This labeled data will serve as the basis for training our logistic regression model.\n",
    "\n",
    "## Logistic Regression\n",
    "Logistic regression is a statistical model that is widely used for binary classification problems. It is particularly suited for scenarios where the dependent variable (the outcome we want to predict) is categorical. In our case, the dependent variable will be the classification of the sonar signals as rocks or mines.\n",
    "\n",
    "By utilizing logistic regression, we can model the relationship between the input features (sonar data) and the output classes (rock or mine). The model will estimate the probability of an object being a rock or a mine based on the given features.\n",
    "\n",
    "## Project Workflow\n",
    "Our project will follow the following workflow:\n",
    "\n",
    "1. Exploratory Data Analysis: We will start by gaining insights into the dataset, examining the features, and performing descriptive analysis to better understand the data.\n",
    "\n",
    "2. Data Preprocessing: This step involves preparing the data for the logistic regression model. We may need to handle missing values, normalize the features, and split the dataset into training and testing sets.\n",
    "\n",
    "3. Model Training: We will train the logistic regression model using the labeled training data. The model will learn to predict the probability of an object being a rock or a mine based on the provided features.\n",
    "\n",
    "4. Model Evaluation: We will assess the performance of our trained model using evaluation metrics such as accuracy, precision, recall, and F1 score. This step will help us understand how well the model generalizes to unseen data.\n",
    "\n",
    "5. Prediction System: Finally, we will use the trained model to make predictions on new, unseen sonar signals. These predictions will determine whether the detected objects are rocks or mines.\n",
    "\n",
    "By following this workflow, we aim to build an accurate and reliable logistic regression model for sonar rock or mine prediction.\n",
    "\n",
    "Let's dive in!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc613cd1",
   "metadata": {},
   "source": [
    "## 1. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a5d4d4",
   "metadata": {},
   "source": [
    "### Importing the required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c06664ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91d76a5",
   "metadata": {},
   "source": [
    "### Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04bfab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('sonar_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c56036b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute_1</th>\n",
       "      <th>attribute_2</th>\n",
       "      <th>attribute_3</th>\n",
       "      <th>attribute_4</th>\n",
       "      <th>attribute_5</th>\n",
       "      <th>attribute_6</th>\n",
       "      <th>attribute_7</th>\n",
       "      <th>attribute_8</th>\n",
       "      <th>attribute_9</th>\n",
       "      <th>attribute_10</th>\n",
       "      <th>...</th>\n",
       "      <th>attribute_52</th>\n",
       "      <th>attribute_53</th>\n",
       "      <th>attribute_54</th>\n",
       "      <th>attribute_55</th>\n",
       "      <th>attribute_56</th>\n",
       "      <th>attribute_57</th>\n",
       "      <th>attribute_58</th>\n",
       "      <th>attribute_59</th>\n",
       "      <th>attribute_60</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   attribute_1  attribute_2  attribute_3  attribute_4  attribute_5   \n",
       "0       0.0200       0.0371       0.0428       0.0207       0.0954  \\\n",
       "1       0.0453       0.0523       0.0843       0.0689       0.1183   \n",
       "2       0.0262       0.0582       0.1099       0.1083       0.0974   \n",
       "3       0.0100       0.0171       0.0623       0.0205       0.0205   \n",
       "4       0.0762       0.0666       0.0481       0.0394       0.0590   \n",
       "\n",
       "   attribute_6  attribute_7  attribute_8  attribute_9  attribute_10  ...   \n",
       "0       0.0986       0.1539       0.1601       0.3109        0.2111  ...  \\\n",
       "1       0.2583       0.2156       0.3481       0.3337        0.2872  ...   \n",
       "2       0.2280       0.2431       0.3771       0.5598        0.6194  ...   \n",
       "3       0.0368       0.1098       0.1276       0.0598        0.1264  ...   \n",
       "4       0.0649       0.1209       0.2467       0.3564        0.4459  ...   \n",
       "\n",
       "   attribute_52  attribute_53  attribute_54  attribute_55  attribute_56   \n",
       "0        0.0027        0.0065        0.0159        0.0072        0.0167  \\\n",
       "1        0.0084        0.0089        0.0048        0.0094        0.0191   \n",
       "2        0.0232        0.0166        0.0095        0.0180        0.0244   \n",
       "3        0.0121        0.0036        0.0150        0.0085        0.0073   \n",
       "4        0.0031        0.0054        0.0105        0.0110        0.0015   \n",
       "\n",
       "   attribute_57  attribute_58  attribute_59  attribute_60  Class  \n",
       "0        0.0180        0.0084        0.0090        0.0032   Rock  \n",
       "1        0.0140        0.0049        0.0052        0.0044   Rock  \n",
       "2        0.0316        0.0164        0.0095        0.0078   Rock  \n",
       "3        0.0050        0.0044        0.0040        0.0117   Rock  \n",
       "4        0.0072        0.0048        0.0107        0.0094   Rock  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6755ca",
   "metadata": {},
   "source": [
    "Here, the features are the sonar signals and Hence they do not possess any specific meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7457d0c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 61)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c223ddc",
   "metadata": {},
   "source": [
    "The info method provides a general insight about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c710a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 208 entries, 0 to 207\n",
      "Data columns (total 61 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   attribute_1   208 non-null    float64\n",
      " 1   attribute_2   208 non-null    float64\n",
      " 2   attribute_3   208 non-null    float64\n",
      " 3   attribute_4   208 non-null    float64\n",
      " 4   attribute_5   208 non-null    float64\n",
      " 5   attribute_6   208 non-null    float64\n",
      " 6   attribute_7   208 non-null    float64\n",
      " 7   attribute_8   208 non-null    float64\n",
      " 8   attribute_9   208 non-null    float64\n",
      " 9   attribute_10  208 non-null    float64\n",
      " 10  attribute_11  208 non-null    float64\n",
      " 11  attribute_12  208 non-null    float64\n",
      " 12  attribute_13  208 non-null    float64\n",
      " 13  attribute_14  208 non-null    float64\n",
      " 14  attribute_15  208 non-null    float64\n",
      " 15  attribute_16  208 non-null    float64\n",
      " 16  attribute_17  208 non-null    float64\n",
      " 17  attribute_18  208 non-null    float64\n",
      " 18  attribute_19  208 non-null    float64\n",
      " 19  attribute_20  208 non-null    float64\n",
      " 20  attribute_21  208 non-null    float64\n",
      " 21  attribute_22  208 non-null    float64\n",
      " 22  attribute_23  208 non-null    float64\n",
      " 23  attribute_24  208 non-null    float64\n",
      " 24  attribute_25  208 non-null    float64\n",
      " 25  attribute_26  208 non-null    float64\n",
      " 26  attribute_27  208 non-null    float64\n",
      " 27  attribute_28  208 non-null    float64\n",
      " 28  attribute_29  208 non-null    float64\n",
      " 29  attribute_30  208 non-null    float64\n",
      " 30  attribute_31  208 non-null    float64\n",
      " 31  attribute_32  208 non-null    float64\n",
      " 32  attribute_33  208 non-null    float64\n",
      " 33  attribute_34  208 non-null    float64\n",
      " 34  attribute_35  208 non-null    float64\n",
      " 35  attribute_36  208 non-null    float64\n",
      " 36  attribute_37  208 non-null    float64\n",
      " 37  attribute_38  208 non-null    float64\n",
      " 38  attribute_39  208 non-null    float64\n",
      " 39  attribute_40  208 non-null    float64\n",
      " 40  attribute_41  208 non-null    float64\n",
      " 41  attribute_42  208 non-null    float64\n",
      " 42  attribute_43  208 non-null    float64\n",
      " 43  attribute_44  208 non-null    float64\n",
      " 44  attribute_45  208 non-null    float64\n",
      " 45  attribute_46  208 non-null    float64\n",
      " 46  attribute_47  208 non-null    float64\n",
      " 47  attribute_48  208 non-null    float64\n",
      " 48  attribute_49  208 non-null    float64\n",
      " 49  attribute_50  208 non-null    float64\n",
      " 50  attribute_51  208 non-null    float64\n",
      " 51  attribute_52  208 non-null    float64\n",
      " 52  attribute_53  208 non-null    float64\n",
      " 53  attribute_54  208 non-null    float64\n",
      " 54  attribute_55  208 non-null    float64\n",
      " 55  attribute_56  208 non-null    float64\n",
      " 56  attribute_57  208 non-null    float64\n",
      " 57  attribute_58  208 non-null    float64\n",
      " 58  attribute_59  208 non-null    float64\n",
      " 59  attribute_60  208 non-null    float64\n",
      " 60  Class         208 non-null    object \n",
      "dtypes: float64(60), object(1)\n",
      "memory usage: 99.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3285c23f",
   "metadata": {},
   "source": [
    "The describe method provides useful statistical analytics of the overall dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9a8a268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute_1</th>\n",
       "      <th>attribute_2</th>\n",
       "      <th>attribute_3</th>\n",
       "      <th>attribute_4</th>\n",
       "      <th>attribute_5</th>\n",
       "      <th>attribute_6</th>\n",
       "      <th>attribute_7</th>\n",
       "      <th>attribute_8</th>\n",
       "      <th>attribute_9</th>\n",
       "      <th>attribute_10</th>\n",
       "      <th>...</th>\n",
       "      <th>attribute_51</th>\n",
       "      <th>attribute_52</th>\n",
       "      <th>attribute_53</th>\n",
       "      <th>attribute_54</th>\n",
       "      <th>attribute_55</th>\n",
       "      <th>attribute_56</th>\n",
       "      <th>attribute_57</th>\n",
       "      <th>attribute_58</th>\n",
       "      <th>attribute_59</th>\n",
       "      <th>attribute_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029164</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0.043832</td>\n",
       "      <td>0.053892</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.104570</td>\n",
       "      <td>0.121747</td>\n",
       "      <td>0.134799</td>\n",
       "      <td>0.178003</td>\n",
       "      <td>0.208259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.006507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.022991</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.046528</td>\n",
       "      <td>0.055552</td>\n",
       "      <td>0.059105</td>\n",
       "      <td>0.061788</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.118387</td>\n",
       "      <td>0.134416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.024375</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.067025</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.080425</td>\n",
       "      <td>0.097025</td>\n",
       "      <td>0.111275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.044050</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.092150</td>\n",
       "      <td>0.106950</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.152250</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.009550</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.035550</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>0.057950</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.100275</td>\n",
       "      <td>0.134125</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.233425</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>0.016725</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.010575</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>0.008525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.682800</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       attribute_1  attribute_2  attribute_3  attribute_4  attribute_5   \n",
       "count   208.000000   208.000000   208.000000   208.000000   208.000000  \\\n",
       "mean      0.029164     0.038437     0.043832     0.053892     0.075202   \n",
       "std       0.022991     0.032960     0.038428     0.046528     0.055552   \n",
       "min       0.001500     0.000600     0.001500     0.005800     0.006700   \n",
       "25%       0.013350     0.016450     0.018950     0.024375     0.038050   \n",
       "50%       0.022800     0.030800     0.034300     0.044050     0.062500   \n",
       "75%       0.035550     0.047950     0.057950     0.064500     0.100275   \n",
       "max       0.137100     0.233900     0.305900     0.426400     0.401000   \n",
       "\n",
       "       attribute_6  attribute_7  attribute_8  attribute_9  attribute_10  ...   \n",
       "count   208.000000   208.000000   208.000000   208.000000    208.000000  ...  \\\n",
       "mean      0.104570     0.121747     0.134799     0.178003      0.208259  ...   \n",
       "std       0.059105     0.061788     0.085152     0.118387      0.134416  ...   \n",
       "min       0.010200     0.003300     0.005500     0.007500      0.011300  ...   \n",
       "25%       0.067025     0.080900     0.080425     0.097025      0.111275  ...   \n",
       "50%       0.092150     0.106950     0.112100     0.152250      0.182400  ...   \n",
       "75%       0.134125     0.154000     0.169600     0.233425      0.268700  ...   \n",
       "max       0.382300     0.372900     0.459000     0.682800      0.710600  ...   \n",
       "\n",
       "       attribute_51  attribute_52  attribute_53  attribute_54  attribute_55   \n",
       "count    208.000000    208.000000    208.000000    208.000000    208.000000  \\\n",
       "mean       0.016069      0.013420      0.010709      0.010941      0.009290   \n",
       "std        0.012008      0.009634      0.007060      0.007301      0.007088   \n",
       "min        0.000000      0.000800      0.000500      0.001000      0.000600   \n",
       "25%        0.008425      0.007275      0.005075      0.005375      0.004150   \n",
       "50%        0.013900      0.011400      0.009550      0.009300      0.007500   \n",
       "75%        0.020825      0.016725      0.014900      0.014500      0.012100   \n",
       "max        0.100400      0.070900      0.039000      0.035200      0.044700   \n",
       "\n",
       "       attribute_56  attribute_57  attribute_58  attribute_59  attribute_60  \n",
       "count    208.000000    208.000000    208.000000    208.000000    208.000000  \n",
       "mean       0.008222      0.007820      0.007949      0.007941      0.006507  \n",
       "std        0.005736      0.005785      0.006470      0.006181      0.005031  \n",
       "min        0.000400      0.000300      0.000300      0.000100      0.000600  \n",
       "25%        0.004400      0.003700      0.003600      0.003675      0.003100  \n",
       "50%        0.006850      0.005950      0.005800      0.006400      0.005300  \n",
       "75%        0.010575      0.010425      0.010350      0.010325      0.008525  \n",
       "max        0.039400      0.035500      0.044000      0.036400      0.043900  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b3b38a",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "Count plot is used to plot the counts of different available categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88f7815b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'Class', data = data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c44a65",
   "metadata": {},
   "source": [
    "The count of class labels is given as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef45c7ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "Mine    111\n",
       "Rock     97\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788209d6",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2c3435",
   "metadata": {},
   "source": [
    "The count of missing values is done below. It is obvious that there are any missing values in the given dataset. \n",
    "\n",
    "So no need for imputation of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9a9defc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "attribute_1     0\n",
       "attribute_2     0\n",
       "attribute_3     0\n",
       "attribute_4     0\n",
       "attribute_5     0\n",
       "               ..\n",
       "attribute_57    0\n",
       "attribute_58    0\n",
       "attribute_59    0\n",
       "attribute_60    0\n",
       "Class           0\n",
       "Length: 61, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6b0b6c",
   "metadata": {},
   "source": [
    "### Data Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774cc54e",
   "metadata": {},
   "source": [
    "Here, the 'Class' column is encoded for training the model. The class label 'Rock' is encoded to 0 and 'Mine' is encoded to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70261bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace({'Class' : {'Rock' : 0, 'Mine' : 1}}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d16a328",
   "metadata": {},
   "source": [
    "###  Data Separation\n",
    "\n",
    "The data is separated into variable X and Y respectively. The X represents as the features vector and Y represents as the label vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71357b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Class', axis = 1)\n",
    "Y = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0e8d406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute_1</th>\n",
       "      <th>attribute_2</th>\n",
       "      <th>attribute_3</th>\n",
       "      <th>attribute_4</th>\n",
       "      <th>attribute_5</th>\n",
       "      <th>attribute_6</th>\n",
       "      <th>attribute_7</th>\n",
       "      <th>attribute_8</th>\n",
       "      <th>attribute_9</th>\n",
       "      <th>attribute_10</th>\n",
       "      <th>...</th>\n",
       "      <th>attribute_51</th>\n",
       "      <th>attribute_52</th>\n",
       "      <th>attribute_53</th>\n",
       "      <th>attribute_54</th>\n",
       "      <th>attribute_55</th>\n",
       "      <th>attribute_56</th>\n",
       "      <th>attribute_57</th>\n",
       "      <th>attribute_58</th>\n",
       "      <th>attribute_59</th>\n",
       "      <th>attribute_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   attribute_1  attribute_2  attribute_3  attribute_4  attribute_5   \n",
       "0       0.0200       0.0371       0.0428       0.0207       0.0954  \\\n",
       "1       0.0453       0.0523       0.0843       0.0689       0.1183   \n",
       "2       0.0262       0.0582       0.1099       0.1083       0.0974   \n",
       "3       0.0100       0.0171       0.0623       0.0205       0.0205   \n",
       "4       0.0762       0.0666       0.0481       0.0394       0.0590   \n",
       "\n",
       "   attribute_6  attribute_7  attribute_8  attribute_9  attribute_10  ...   \n",
       "0       0.0986       0.1539       0.1601       0.3109        0.2111  ...  \\\n",
       "1       0.2583       0.2156       0.3481       0.3337        0.2872  ...   \n",
       "2       0.2280       0.2431       0.3771       0.5598        0.6194  ...   \n",
       "3       0.0368       0.1098       0.1276       0.0598        0.1264  ...   \n",
       "4       0.0649       0.1209       0.2467       0.3564        0.4459  ...   \n",
       "\n",
       "   attribute_51  attribute_52  attribute_53  attribute_54  attribute_55   \n",
       "0        0.0232        0.0027        0.0065        0.0159        0.0072  \\\n",
       "1        0.0125        0.0084        0.0089        0.0048        0.0094   \n",
       "2        0.0033        0.0232        0.0166        0.0095        0.0180   \n",
       "3        0.0241        0.0121        0.0036        0.0150        0.0085   \n",
       "4        0.0156        0.0031        0.0054        0.0105        0.0110   \n",
       "\n",
       "   attribute_56  attribute_57  attribute_58  attribute_59  attribute_60  \n",
       "0        0.0167        0.0180        0.0084        0.0090        0.0032  \n",
       "1        0.0191        0.0140        0.0049        0.0052        0.0044  \n",
       "2        0.0244        0.0316        0.0164        0.0095        0.0078  \n",
       "3        0.0073        0.0050        0.0044        0.0040        0.0117  \n",
       "4        0.0015        0.0072        0.0048        0.0107        0.0094  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81fe823",
   "metadata": {},
   "source": [
    "Since the values of the features are in the range of 0 to 1, there is no need for data normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f9356b",
   "metadata": {},
   "source": [
    "### Splitting the dataset\n",
    "\n",
    "The dataset is splitted into training and testing data respectively. \n",
    "\n",
    "#### Note: \n",
    "The training data consists of 90% of the entire dataset, whereas the testing data consists of remaining 10% of the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61a288b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.1, stratify = Y, random_state = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1d442e",
   "metadata": {},
   "source": [
    "## 3. Model Training\n",
    "\n",
    "### Logistic Regression\n",
    "\n",
    "Logistic regression is a popular statistical model used for binary classification tasks. It is widely used in machine learning to predict the probability of an event occurring based on given input features. In logistic regression, the dependent variable is categorical and represents the classes or labels to be predicted.\n",
    "\n",
    "### Formula\n",
    "\n",
    "The logistic regression model uses the logistic function, also known as the sigmoid function, to estimate the probability of the binary outcome. The sigmoid function maps any real-valued number to a value between 0 and 1. The formula for logistic regression can be expressed as:\n",
    "\n",
    "![Logistic Regression Formula](https://latex.codecogs.com/png.latex?%5Cdpi%7B150%7D%20P%28Y%3D1%7CX%29%20%3D%20%5Cfrac%7B1%7D%7B1%20&plus;%20e%5E%7B-%28%5Cbeta_0%20&plus;%20%5Cbeta_1X_1%20&plus;%20%5Cbeta_2X_2%20&plus;%20...%20&plus;%20%5Cbeta_nX_n%29%7D%7D)\n",
    "\n",
    "- **P(Y=1|X)** represents the probability of the binary outcome (Y) being 1 given the input features (X).\n",
    "- **β0, β1, β2, ..., βn** are the coefficients (parameters) estimated by the logistic regression model.\n",
    "- **X1, X2, ..., Xn** are the input features.\n",
    "\n",
    "The logistic regression model uses an optimization algorithm (such as maximum likelihood estimation) to estimate the coefficients that best fit the training data.\n",
    "\n",
    "### Training the Logistic Regression Model\n",
    "\n",
    "To train a logistic regression model, we typically use a dataset with labeled examples, where each example consists of input features and the corresponding binary outcome. The model learns the optimal values of the coefficients that maximize the likelihood of the observed data.\n",
    "\n",
    "During the training process, the model iteratively updates the coefficients using an optimization algorithm. This process continues until convergence, where the coefficients stabilize and the model achieves the best fit to the training data.\n",
    "\n",
    "### Decision Boundary and Predictions\n",
    "\n",
    "Once the logistic regression model is trained, it can be used to make predictions on new, unseen examples. The model calculates the probability of the binary outcome being 1 based on the input features. By applying a decision boundary (typically 0.5), the model assigns the example to either class 1 or class 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb8875e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class regression:\n",
    "    def __init__(self):\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "    def fit(self, X, Y, alpha, iterations):\n",
    "        samples, features = X.shape\n",
    "        self.weights = np.zeros(features)\n",
    "        self.bias = 0\n",
    "        for i in range(iterations):\n",
    "            z = np.dot(X, self.weights) + self.bias\n",
    "            y_pred = 1 / (1 + np.exp(-1 * z))\n",
    "            dw = (1 / samples) * np.dot(X.T, (y_pred - Y))\n",
    "            db = (1 / samples) * np.sum(y_pred - Y)\n",
    "            self.weights -= alpha * dw\n",
    "            self.bias -= alpha * db\n",
    "    def predict(self, X):\n",
    "        z = np.dot(X, self.weights) + self.bias\n",
    "        return (1 / (1 + np.exp(-1 * z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48faa5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = regression()\n",
    "model.fit(x_train, y_train, 0.01, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79fecb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(x_train) #Prediction values for training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f9d6e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximating the values according to the decision boundary\n",
    "pred = []\n",
    "for i in res:\n",
    "    if i >= 0.5:\n",
    "        pred.append(1)\n",
    "    else:\n",
    "        pred.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994ef4f2",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation\n",
    "\n",
    "To evaluate the performance of a logistic regression model, various evaluation metrics can be used, such as accuracy, precision, recall, and F1 score. These metrics assess how well the model predicts the binary outcome compared to the true labels. However, I've evaluated the model only with the metric accuracy.\n",
    "\n",
    "### Accuracy\n",
    "\n",
    "In machine learning, accuracy is a commonly used metric to evaluate the performance of a classification model. Accuracy measures the proportion of correctly predicted instances out of the total number of instances.\n",
    "\n",
    "### Formula\n",
    "\n",
    "The formula for accuracy is:\n",
    "\n",
    "![Accuracy Formula](https://latex.codecogs.com/png.latex?%5Cdpi%7B150%7D%20%5Ctext%7BAccuracy%7D%20%3D%20%5Cfrac%7B%5Ctext%7BCorrect%20Predictions%7D%7D%7B%5Ctext%7BTotal%20Predictions%7D%7D)\n",
    "\n",
    "where:\n",
    "- **Correct Predictions**: the number of instances that are correctly classified by the model.\n",
    "- **Total Predictions**: the total number of instances in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33079d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8021390374331551"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pred == y_train) / len(y_train) #Accuracy for the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e1820f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92772799, 0.05212851, 0.59786425, 0.48247816, 0.74148117,\n",
       "       0.7743676 , 0.288057  , 0.30858644, 0.87634246, 0.6027003 ,\n",
       "       0.35793606, 0.61047649, 0.40542389, 0.50334014, 0.84413621,\n",
       "       0.81247203, 0.4278414 , 0.83056756, 0.53925464, 0.17766009,\n",
       "       0.20541268])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the testing set is predicted as follows\n",
    "res_test = model.predict(x_test)\n",
    "res_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45cae3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_test = np.where(res_test >= 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31d84241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7619047619047619"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(res_test == y_test) / len(y_test) #Accuracy for the testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3906fb6b",
   "metadata": {},
   "source": [
    "### Precision\n",
    "\n",
    "Precision measures the proportion of correctly predicted positive instances out of the total instances predicted as positive. It helps assess the model's accuracy in classifying positive instances.\n",
    "\n",
    "The formula for precision is:\n",
    "\n",
    "![Precision Formula](https://latex.codecogs.com/png.latex?%5Cdpi%7B150%7D%20%5Ctext%7BPrecision%7D%20%3D%20%5Cfrac%7B%5Ctext%7BTrue%20Positives%7D%7D%7B%5Ctext%7BTrue%20Positives%7D%20&plus;%20%5Ctext%7BFalse%20Positives%7D%7D)\n",
    "\n",
    "### Recall\n",
    "\n",
    "Recall, also known as sensitivity or true positive rate, measures the proportion of correctly predicted positive instances out of all actual positive instances. It helps evaluate the model's ability to capture positive instances.\n",
    "\n",
    "The formula for recall is:\n",
    "\n",
    "![Recall Formula](https://latex.codecogs.com/png.latex?%5Cdpi%7B150%7D%20%5Ctext%7BRecall%7D%20%3D%20%5Cfrac%7B%5Ctext%7BTrue%20Positives%7D%7D%7B%5Ctext%7BTrue%20Positives%7D%20&plus;%20%5Ctext%7BFalse%20Negatives%7D%7D)\n",
    "\n",
    "### F1 Score\n",
    "\n",
    "The F1 score is the harmonic mean of precision and recall. It provides a balanced measure of the model's performance by considering both precision and recall.\n",
    "\n",
    "The formula for the F1 score is:\n",
    "\n",
    "![F1 Score Formula](https://latex.codecogs.com/png.latex?%5Cdpi%7B150%7D%20%5Ctext%7BF1%20Score%7D%20%3D%20%5Cfrac%7B2%20%5Ctimes%20%5Ctext%7BPrecision%7D%20%5Ctimes%20%5Ctext%7BRecall%7D%7D%7B%5Ctext%7BPrecision%7D%20&plus;%20%5Ctext%7BRecall%7D%7D)\n",
    "\n",
    "### Code for Calculating Precision, Recall, and F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f444f217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.78\n",
      "Recall:  0.88\n",
      "F1 Score: 0.83\n"
     ]
    }
   ],
   "source": [
    "def calculate_precision(true_positives, false_positives):\n",
    "    return true_positives / (true_positives + false_positives)\n",
    "\n",
    "def calculate_recall(true_positives, false_negatives):\n",
    "    return true_positives / (true_positives + false_negatives)\n",
    "\n",
    "def calculate_f1_score(precision, recall):\n",
    "    return (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "\n",
    "# Calculate true positives, false positives, and false negatives\n",
    "true_positives = sum([1 for true, pred in zip(y_train, pred) if true == 1 and pred == 1])\n",
    "false_positives = sum([1 for true, pred in zip(y_train, pred) if true == 0 and pred == 1])\n",
    "false_negatives = sum([1 for true, pred in zip(y_train, pred) if true == 1 and pred == 0])\n",
    "\n",
    "# Calculate precision\n",
    "precision = calculate_precision(true_positives, false_positives)\n",
    "\n",
    "# Calculate recall\n",
    "recall = calculate_recall(true_positives, false_negatives)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1_score = calculate_f1_score(precision, recall)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall:  {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abc61f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The metrics for test set\n",
      "Precision: 0.75\n",
      "Recall:  0.82\n",
      "F1 Score: 0.78\n"
     ]
    }
   ],
   "source": [
    "# Calculate true positives, false positives, and false negatives for test data\n",
    "\n",
    "true_positives_test = sum([1 for true, pred in zip(y_test, res_test) if true == 1 and pred == 1])\n",
    "false_positives_test = sum([1 for true, pred in zip(y_test, res_test) if true == 0 and pred == 1])\n",
    "false_negatives_test = sum([1 for true, pred in zip(y_test, res_test) if true == 1 and pred == 0])\n",
    "\n",
    "# Calculate precision for test set\n",
    "precision_test = calculate_precision(true_positives_test, false_positives_test)\n",
    "\n",
    "# Calculate recall for test set\n",
    "recall_test = calculate_recall(true_positives_test, false_negatives_test)\n",
    "\n",
    "# Calculate F1 score for test\n",
    "f1_score_test = calculate_f1_score(precision_test, recall_test)\n",
    "\n",
    "\n",
    "print(\"The metrics for test set\")\n",
    "print(f\"Precision: {precision_test:.2f}\")\n",
    "print(f\"Recall:  {recall_test:.2f}\")\n",
    "print(f\"F1 Score: {f1_score_test:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90373ee",
   "metadata": {},
   "source": [
    "Hence, these are the evaluation metrics for the logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683d2679",
   "metadata": {},
   "source": [
    "## 5. Prediction System\n",
    "\n",
    "Once you have developed and trained your logistic regression model for sonar rock or mine classification, I've created to take new input values and predict whether the sonar detects a rock or a mine.\n",
    "\n",
    "### Input Values\n",
    "1. Provide the necessary input values for the sonar signals that you want to classify as rocks or mines. These values should correspond to the same features that were used during training.\n",
    "2. You can either input the values manually or load them from an external source, such as a CSV file or another dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5f41325",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_data = pd.Series([0.0599,0.0474,0.0498,0.0387,0.1026,0.0773,0.0853,0.0447,0.1094,0.0351,0.1582,0.2023,0.2268,0.2829,0.3819,0.4665,0.6687,0.8647,0.9361,0.9367,0.9144,0.9162,0.9311,0.8604,0.7327,0.5763,0.4162,0.4113,0.4146,0.3149,0.2936,0.3169,0.3149,0.4132,0.3994,0.4195,0.4532,0.4419,0.4737,0.3431,0.3194,0.337,0.2493,0.265,0.1748,0.0932,0.053,0.0081,0.0342,0.0137,0.0028,0.0013,0.0005,0.0227,0.0209,0.0081,0.0117,0.0114,0.0112,0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91a8eb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mine It is! Be Careful\n"
     ]
    }
   ],
   "source": [
    "print(\"Mine It is! Be Careful\" if model.predict(x_test_data) >= 0.5 else \"Don't Worry It's just a Rock (Dwayne Johnson)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55663dcf",
   "metadata": {},
   "source": [
    "Hence, this predictive system can be used with the unseen input data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db232d4",
   "metadata": {},
   "source": [
    "\n",
    "# The End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
